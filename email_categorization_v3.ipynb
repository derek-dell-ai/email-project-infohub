{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b86eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using CUDA - Accelerated data analysis for GPU\n",
    "import cudf\n",
    "\n",
    "# Loading the emails\n",
    "df = cudf.read_csv('../data/emails.csv')\n",
    "\n",
    "# Printing out the first three rows\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ab4fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a look at how many emails\n",
    "print(f\"The DataFrame has {df.shape[0]} emails.\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4b70e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "The DataFrame has 517401 emails.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b08ca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove metadata (headers) and keep only the email body\n",
    "def clean_email_body(message):\n",
    "    # Split the message at the first blank line (using \\n) to separate headers from the body\n",
    "    body = cudf.Series(message).str.split('\\n\\n', expand=True)[1]\n",
    "    return body.str.replace(r'[^a-zA-Z\\s]', '', regex=True).str.lower()\n",
    "\n",
    "# Apply the cleaning function\n",
    "df['cleaned_message'] = clean_email_body(df['message'])\n",
    "\n",
    "# Check the cleaned message column\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eed9026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Categories with associated keywords (just data engineering, not ML but shows how quickly rapids works)\n",
    "categories = {\n",
    "    'important': ['deadline', 'asap', 'critical', 'urgent', 'quickly'],\n",
    "    'illegal': ['money laundering', 'scam', 'tax fraud', 'payoff', 'shady'],\n",
    "    'phishing': ['account verification', 'verify your identity', 'suspicious activity'],\n",
    "    'spam': ['win', 'offer', 'free', 'click here'],\n",
    "    'routine': ['meeting', 'catch up', 'hello', 'update'],\n",
    "}\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "# Create a new column to store the category\n",
    "df['category'] = 'regular'  # Initialize all emails as regular\n",
    "\n",
    "# Iterate over each category and its associated keywords\n",
    "for category, keywords in categories.items():\n",
    "    # Create a mask where any keyword matches in the cleaned_message\n",
    "    mask = df['cleaned_message'].str.contains('|'.join(keywords), regex=True)\n",
    "    \n",
    "    # Assign the category to rows where the mask is True\n",
    "    df['category'] = df['category'].where(~mask, other=category)\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the time taken for the operation\n",
    "print(f\"Time taken for categorization: {end_time - start_time} seconds\")\n",
    "\n",
    "# Newline Print\n",
    "print('\\n')\n",
    "\n",
    "# Check the first few categorized emails\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab6c930",
   "metadata": {},
   "outputs": [],
   "source": [
    "Time taken for categorization: 2.8526015281677246 seconds\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab2dc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5278ac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "category\n",
    "regular      448437\n",
    "spam          33698\n",
    "routine       31039\n",
    "important      4161\n",
    "illegal          62\n",
    "phishing          4\n",
    "Name: count, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfddde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the DataFrame to the specified directory because I need to use the GPU for LLMs, ordinarily you'd have a separate server\n",
    "df.to_csv('../data/emails_cleaned_v2.csv', index=False)\n",
    "print('Exported')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6089d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "Exported\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094efbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the clean emails, no GPU so I did not use cuDF\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV into a pandas DataFrame\n",
    "df = pd.read_csv('../data/emails_cleaned.csv')\n",
    "\n",
    "# Check the first few rows\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b53a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to my Llama3.1 NIM \n",
    "from openai import OpenAI\n",
    "\n",
    "# Set up the OpenAI client with the local NIM instance (remove IP)\n",
    "client = OpenAI(\n",
    "    base_url=\"http://172.29.202.76:8000/v1\",  \n",
    "    api_key=\"dummy_api_key\"  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c63517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting knowledge using the LLM with a fallback for short emails\n",
    "def extract_knowledge(email_text):\n",
    "    system_prompt = \"You are an expert in extracting key facts and insights from emails.\"\n",
    "\n",
    "    # Define a threshold for what we consider \"short\"\n",
    "    word_count = len(email_text.split())\n",
    "    if word_count < 10:  # Threshold for short emails (originally was 5)\n",
    "        return \"The email content is too brief to extract meaningful knowledge.\"\n",
    "\n",
    "    # Knowledge extraction prompt for regular emails\n",
    "    user_prompt = f\"\"\"Extract the key pieces of information from the following email:\n",
    "    \n",
    "    Email content: \"{email_text}\"\n",
    "    \n",
    "    Identify any important facts, dates, names, instructions, or other relevant information. Summarize the key knowledge from this email.\"\"\"\n",
    "\n",
    "    # Create a chat completion request to the LLM\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"meta/llama-3.1-8b-instruct\",  # Your model\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        top_p=0.7,\n",
    "        max_tokens=250,\n",
    "        stream=False  \n",
    "    )\n",
    "\n",
    "    # Extract the message content from the response\n",
    "    knowledge_content = \"\"\n",
    "    for choice in completion.choices:\n",
    "        knowledge_content += choice.message.content\n",
    "    \n",
    "    return knowledge_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c4e3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Fill any missing or NaN values in the 'cleaned_message' column with a default string\n",
    "df['cleaned_message'] = df['cleaned_message'].fillna('')\n",
    "\n",
    "# Apply the function to the first 100 emails and time the process\n",
    "start_time = time.time()\n",
    "\n",
    "# Subset the first 100 emails and create a copy to avoid SettingWithCopyWarning\n",
    "df_subset = df.head(100).copy()\n",
    "\n",
    "# Apply the extract_knowledge function using .loc[] to avoid the warning\n",
    "df_subset.loc[:, 'extracted_knowledge'] = df_subset['cleaned_message'].apply(extract_knowledge)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the time taken\n",
    "print(f\"Time taken for extracting knowledge from 100 emails: {end_time - start_time} seconds\")\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "df_subset.to_csv('../data/emails_with_extracted_knowledge_100_v1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeb6e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Time taken for extracting knowledge from 100 emails: 26.8750741481781 seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d384581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It would take roughly 39hrs to go through all 517k emails at that speed (less than a weekend) for full categorization and knowledge extraction from these emails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f45aea",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
